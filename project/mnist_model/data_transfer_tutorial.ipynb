{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cf1b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "assert torch.cuda.is_available(), \"CUDA is not available. Please check your PyTorch installation.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba7acdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/dill-0.3.9-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.2.dev0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_utilities-0.14.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/looseversion-1.3.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/nvfuser-0.2.26a0+c5e1555-py3.12-linux-x86_64.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/opt_einsum-3.4.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: tensordict in /home/benilla/.local/lib/python3.12/site-packages (0.9.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from tensordict) (2.7.0a0+7c8ec84dab.nv25.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from tensordict) (1.26.4)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from tensordict) (3.1.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensordict) (23.2)\n",
      "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.12/dist-packages/setuptools/_vendor (from tensordict) (8.0.0)\n",
      "Requirement already satisfied: orjson in /usr/local/lib/python3.12/dist-packages (from tensordict) (3.10.18)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.12/dist-packages/setuptools/_vendor (from importlib_metadata->tensordict) (3.19.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->tensordict) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->tensordict) (4.12.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->tensordict) (75.8.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.12/dist-packages (from torch->tensordict) (1.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->tensordict) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->tensordict) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->tensordict) (2025.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch->tensordict) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->tensordict) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "# Install tensordict with the following command\n",
    "!pip3 install tensordict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0e9e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158a8620",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "\n",
    "from torch.cuda import Stream\n",
    "\n",
    "\n",
    "s = Stream()\n",
    "\n",
    "torch.manual_seed(42)\n",
    "t1_cpu_pinned = torch.randn(1024**2 * 5, pin_memory=True)\n",
    "t2_cpu_paged = torch.randn(1024**2 * 5, pin_memory=False)\n",
    "t3_cuda = torch.randn(1024**2 * 5, device=\"cuda:0\")\n",
    "\n",
    "assert torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\", torch.cuda.current_device())\n",
    "\n",
    "\n",
    "# The function we want to profile\n",
    "def inner(pinned: bool, streamed: bool):\n",
    "    with torch.cuda.stream(s) if streamed else contextlib.nullcontext():\n",
    "        if pinned:\n",
    "            t1_cuda = t1_cpu_pinned.to(device, non_blocking=True)\n",
    "        else:\n",
    "            t2_cuda = t2_cpu_paged.to(device, non_blocking=True)\n",
    "        t_star_cuda_h2d_event = s.record_event()\n",
    "    # This operation can be executed during the CPU to GPU copy if and only if the tensor is pinned and the copy is\n",
    "    #  done in the other stream\n",
    "    t3_cuda_mul = t3_cuda * t3_cuda * t3_cuda\n",
    "    t3_cuda_h2d_event = torch.cuda.current_stream().record_event()\n",
    "    t_star_cuda_h2d_event.synchronize()\n",
    "    t3_cuda_h2d_event.synchronize()\n",
    "\n",
    "\n",
    "# Our profiler: profiles the `inner` function and stores the results in a .json file\n",
    "def benchmark_with_profiler(\n",
    "    pinned,\n",
    "    streamed,\n",
    ") -> None:\n",
    "    torch._C._profiler._set_cuda_sync_enabled_val(True)\n",
    "    wait, warmup, active = 1, 1, 2\n",
    "    num_steps = wait + warmup + active\n",
    "    rank = 0\n",
    "    with torch.profiler.profile(\n",
    "        activities=[\n",
    "            torch.profiler.ProfilerActivity.CPU,\n",
    "            torch.profiler.ProfilerActivity.CUDA,\n",
    "        ],\n",
    "        schedule=torch.profiler.schedule(\n",
    "            wait=wait, warmup=warmup, active=active, repeat=1, skip_first=1\n",
    "        ),\n",
    "    ) as prof:\n",
    "        for step_idx in range(1, num_steps + 1):\n",
    "            inner(streamed=streamed, pinned=pinned)\n",
    "            if rank is None or rank == 0:\n",
    "                prof.step()\n",
    "    prof.export_chrome_trace(f\"trace_streamed{int(streamed)}_pinned{int(pinned)}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f7d722",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't3_cuda' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mbenchmark_with_profiler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstreamed\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpinned\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 52\u001b[39m, in \u001b[36mbenchmark_with_profiler\u001b[39m\u001b[34m(pinned, streamed)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.profiler.profile(\n\u001b[32m     43\u001b[39m     activities=[\n\u001b[32m     44\u001b[39m         torch.profiler.ProfilerActivity.CPU,\n\u001b[32m   (...)\u001b[39m\u001b[32m     49\u001b[39m     ),\n\u001b[32m     50\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m prof:\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m step_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, num_steps + \u001b[32m1\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstreamed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstreamed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpinned\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpinned\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m rank \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m rank == \u001b[32m0\u001b[39m:\n\u001b[32m     54\u001b[39m             prof.step()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36minner\u001b[39m\u001b[34m(pinned, streamed)\u001b[39m\n\u001b[32m     24\u001b[39m     t_star_cuda_h2d_event = s.record_event()\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# This operation can be executed during the CPU to GPU copy if and only if the tensor is pinned and the copy is\u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m#  done in the other stream\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m t3_cuda_mul = \u001b[43mt3_cuda\u001b[49m * t3_cuda * t3_cuda\n\u001b[32m     28\u001b[39m t3_cuda_h2d_event = torch.cuda.current_stream().record_event()\n\u001b[32m     29\u001b[39m t_star_cuda_h2d_event.synchronize()\n",
      "\u001b[31mNameError\u001b[39m: name 't3_cuda' is not defined"
     ]
    }
   ],
   "source": [
    "benchmark_with_profiler(streamed=False, pinned=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
