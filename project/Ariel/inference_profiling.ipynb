{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d07683c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gc \n",
    "from pathlib import Path\n",
    "import torch \n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.utils.benchmark as benchmark\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import contextlib\n",
    "from torch.cuda import Stream\n",
    "\n",
    "from mnist_model import NeuralNetwork\n",
    "from mnist_train import train_epoch, evaluate\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "01f33858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use available device\n",
    "\n",
    "device = torch.device(\"cuda:2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f524b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=64, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#perform inference on cuda \n",
    "#import trained model \n",
    "\n",
    "model =NeuralNetwork().to(device)\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40226313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('mnist_model.pth')) # Load the saved model weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270b0f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=64, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval() # Set the model to evaluation mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f555431",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea1bedf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f75983bc3f0>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f30c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "s=Stream()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8603569d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_profiling_async():\n",
    "    tensors= [torch.randn(1,28,28,pin_memory=True) for _ in range(10000)]\n",
    "\n",
    "    # perform inference on data in gpu\n",
    "    start_async = time.time()\n",
    "\n",
    "\n",
    "    s=Stream()\n",
    "\n",
    "    with torch.cuda.stream(s):\n",
    "        # perform async copy \n",
    "        \n",
    "        result= []\n",
    "        for tensor in tensors:\n",
    "            tensor=tensor.to(device,non_blocking=True)\n",
    "            result.append(tensor)\n",
    "            \n",
    "\n",
    "        tensors_h2d_event=s.record_event() # record event when copy is done\n",
    "\n",
    "    #meaning we have no gradients to compute. ie only doing forward pass\n",
    "    with torch.no_grad():\n",
    "        for tensor in result:\n",
    "            output_sync=model(tensor)\n",
    "        \n",
    "        model_infer_event=torch.cuda.current_stream().record_event() # record event when inference is done\n",
    "\n",
    "    tensors_h2d_event.synchronize() # wait for all kernels in all streams to complete\n",
    "    model_infer_event.synchronize() # wait for all kernels in all streams to complete\n",
    "\n",
    "    end_async = time.time()\n",
    "    async_time = end_async - start_async\n",
    "    print(f\"Asynchronous copy and inference time: {async_time:.6f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343fb3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_profiling_sync():\n",
    "    #perform sync copy (called explicitly)\n",
    "    tensors= [torch.randn(1,28,28,pin_memory=False) for _ in range(10000)]\n",
    "\n",
    "    start_sync = time.time()\n",
    "    #meaning we have no gradients to compute. ie only doing forward pass\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        result= []\n",
    "        # send tensors to GPU \n",
    "        for tensor in tensors:\n",
    "            tensor=tensor.to(device,non_blocking=False)\n",
    "            result.append(tensor)\n",
    "       \n",
    "        for tensor in result:\n",
    "            output_sync=model(tensor)\n",
    "    end_sync = time.time()\n",
    "    sync_time = end_sync - start_sync\n",
    "    print(f\"Synchronous copy and inference time: {sync_time:.6f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042d3993",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2=benchmark.Timer(\n",
    "    stmt=\"inference_profiling_async()\",\n",
    "    setup=\"from __main__ import inference_profiling_async\",\n",
    "    num_threads=torch.get_num_threads(),\n",
    "    label=\"ASYNC copy + inference\",\n",
    "    sub_label=\"transfer to GPU + inference\",\n",
    ")\n",
    "\n",
    "t3=benchmark.Timer(\n",
    "    stmt=\"inference_profiling_sync()\",\n",
    "    setup=\"from __main__ import inference_profiling_sync\",\n",
    "    num_threads=torch.get_num_threads(),\n",
    "    label=\"SYNC copy + inference\",\n",
    "    sub_label=\"transfer to GPU + inference\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad2e325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asynchronous copy and inference time: 1.575929 seconds\n",
      "Asynchronous copy and inference time: 1.468861 seconds\n",
      "Asynchronous copy and inference time: 1.455780 seconds\n",
      "Asynchronous copy and inference time: 1.457217 seconds\n",
      "Asynchronous copy and inference time: 1.455045 seconds\n",
      "Asynchronous copy and inference time: 1.455118 seconds\n",
      "Asynchronous copy and inference time: 1.454524 seconds\n",
      "Asynchronous copy and inference time: 1.456453 seconds\n",
      "Asynchronous copy and inference time: 1.457391 seconds\n",
      "Asynchronous copy and inference time: 1.457894 seconds\n",
      "Asynchronous copy and inference time: 1.453143 seconds\n",
      "Asynchronous copy and inference time: 1.452112 seconds\n",
      "<torch.utils.benchmark.utils.common.Measurement object at 0x7f76b9a058b0>\n",
      "ASYNC copy + inference: transfer to GPU + inference\n",
      "setup: from __main__ import inference_profiling_async\n",
      "  1.60 s\n",
      "  1 measurement, 10 runs , 24 threads\n",
      "Synchronous copy and inference time: 1.483008 seconds\n",
      "Synchronous copy and inference time: 1.477060 seconds\n",
      "Synchronous copy and inference time: 1.485503 seconds\n",
      "Synchronous copy and inference time: 1.485182 seconds\n",
      "Synchronous copy and inference time: 1.482512 seconds\n",
      "Synchronous copy and inference time: 1.485441 seconds\n",
      "Synchronous copy and inference time: 1.485229 seconds\n",
      "Synchronous copy and inference time: 1.484079 seconds\n",
      "Synchronous copy and inference time: 1.487258 seconds\n",
      "Synchronous copy and inference time: 1.482742 seconds\n",
      "Synchronous copy and inference time: 1.486720 seconds\n",
      "Synchronous copy and inference time: 1.484755 seconds\n",
      "<torch.utils.benchmark.utils.common.Measurement object at 0x7f76b9a058b0>\n",
      "SYNC copy + inference: transfer to GPU + inference\n",
      "setup: from __main__ import inference_profiling_sync\n",
      "  1.61 s\n",
      "  1 measurement, 10 runs , 24 threads\n"
     ]
    }
   ],
   "source": [
    "print(t2.timeit(10))\n",
    "print(t3.timeit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f12640",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:2 and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[92]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m tensors:\n\u001b[32m      7\u001b[39m         tensor=tensor.to(\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;66;03m#implicit synchronization here \u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m         output_sync=\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m end_implicit = time.time()\n\u001b[32m     10\u001b[39m implicit_time = end_implicit - start_implicit\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/workspace/benilla/mnist_model/mnist_model.py:26\u001b[39m, in \u001b[36mNeuralNetwork.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch.Tensor) -> torch.Tensor:\n\u001b[32m     25\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.flatten(x)\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Expected all tensors to be on the same device, but found at least two devices, cuda:2 and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)"
     ]
    }
   ],
   "source": [
    "#implicit synchronization\n",
    "start_implicit = time.time()\n",
    "\n",
    "tensors= [torch.randn(1,1,28,28) for _ in range(1000)]\n",
    "with torch.no_grad():\n",
    "    for tensor in tensors:\n",
    "        tensor=tensor.to(\"cuda\") #implicit synchronization here \n",
    "        output_sync=model(tensor)\n",
    "end_implicit = time.time()\n",
    "implicit_time = end_implicit - start_implicit\n",
    "print(f\"Implicit synchronization copy and inference time: {implicit_time:.6f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
